{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec202ada",
   "metadata": {},
   "source": [
    "# Assignment2 - Supervised Learning flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06a2810",
   "metadata": {},
   "source": [
    "# Part 1 - Student details:\n",
    "* Please write the First Name and last 4 digits of the i.d. for each student. For example:\n",
    "<pre>Israel 9812</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca16486b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# student 1: idan 4202\n",
    "# student 2: guy 6303"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df67c2ee-87c8-499c-a04f-1853c332f51d",
   "metadata": {},
   "source": [
    "## Part 2 - Initial Preparations \n",
    "You could add as many code cells as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29b3454-b568-4614-8017-f15b3c59fc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Loading the datasets\n",
    "train_data = pd.read_csv('housing_train.csv')  # Loading training dataset\n",
    "test_data = pd.read_csv('housing_test.csv')  # Loading testing dataset\n",
    "\n",
    "# Displaying first few rows of both datasets\n",
    "print(train_data.head())\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb36672a",
   "metadata": {},
   "source": [
    "## Part 3 - Experiments\n",
    "You could add as many code cells as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7098585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "# Creating new features by transforming and combining existing features\n",
    "train_data['MedInc^2'] = train_data['MedInc'] ** 2  # Creating a new feature as the square of 'MedInc' in training data\n",
    "test_data['MedInc^2'] = test_data['MedInc'] ** 2  # Creating the same feature in test data\n",
    "\n",
    "train_data['PopRoom'] = train_data['Population'] / train_data['AveRooms']  # Creating a feature by dividing 'Population' by 'AveRooms'\n",
    "test_data['PopRoom'] = test_data['Population'] / test_data['AveRooms']\n",
    "\n",
    "train_data['log_MedInc'] = np.log(train_data['MedInc'])  # Applying log transformation to 'MedInc'\n",
    "test_data['log_MedInc'] = np.log(test_data['MedInc'])\n",
    "\n",
    "train_data['RoomsPerHouse'] = train_data['AveRooms'] / train_data['AveOccup']  # Ratio of 'AveRooms' to 'AveOccup'\n",
    "test_data['RoomsPerHouse'] = test_data['AveRooms'] / test_data['AveOccup']\n",
    "\n",
    "train_data['BedroomsPerRoom'] = train_data['AveBedrms'] / train_data['AveRooms']  # Ratio of 'AveBedrms' to 'AveRooms'\n",
    "test_data['BedroomsPerRoom'] = test_data['AveBedrms'] / test_data['AveRooms']\n",
    "\n",
    "# Clustering to create 'LocationCluster'\n",
    "from sklearn.cluster import KMeans  # Importing KMeans clustering\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)  # Setting KMeans with 5 clusters\n",
    "train_data['LocationCluster'] = kmeans.fit_predict(train_data[['Latitude', 'Longitude']])  # Creating location-based clusters for training data\n",
    "test_data['LocationCluster'] = kmeans.predict(test_data[['Latitude', 'Longitude']])  # Assigning clusters to test data\n",
    "\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097afb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into features and target\n",
    "X_train = train_data.drop('MedHouseVal', axis=1)  # Dropping the target column from training data to get features\n",
    "y_train = train_data['MedHouseVal']  # Storing the target column separately\n",
    "X_test = test_data.drop('MedHouseVal', axis=1)  # Dropping target from test data as well\n",
    "\n",
    "# Scaling the features\n",
    "scaler = StandardScaler()  # Initializing the StandardScaler for normalization\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Scaling the training features\n",
    "X_test_scaled = scaler.transform(X_test)  # Scaling the test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa9ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor model\n",
    "model_rf = RandomForestRegressor(n_estimators=100)  # Initializing RandomForestRegressor with 100 trees\n",
    "model_rf.fit(X_train_scaled, y_train)  # Fitting the model to training data\n",
    "y_pred = model_rf.predict(X_test_scaled)  # Making predictions on the test set\n",
    "\n",
    "# Print the first five predictions\n",
    "print(\"Predictions on test set: \", y_pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937b653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic statistics of the training data such as mean, standard deviation, min, max, etc.\n",
    "print(train_data.describe())\n",
    "\n",
    "# Plot a scatter plot showing the relationship between Median Income and Median House Value\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=train_data['MedInc'], y=train_data['MedHouseVal'])\n",
    "plt.title('Median Income vs Median House Value')  # Set the title for the plot\n",
    "plt.show()  # Display the plot\n",
    "\n",
    "# Plot a histogram showing the distribution of House Age in the dataset with a KDE (Kernel Density Estimate) for smoothness\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(train_data['HouseAge'], bins=30, kde=True)  # 30 bins in the histogram, KDE for smoothing\n",
    "plt.title('Distribution of House Age')  # Set the title for the plot\n",
    "plt.show()  # Display the plot\n",
    "\n",
    "# Plot a heatmap showing the correlation between the different features in the dataset\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(train_data.corr(), annot=True, cmap=\"coolwarm\", fmt='.2f')  # 'coolwarm' color map, 2 decimal places for annotations\n",
    "plt.title('Correlation Heatmap of Features')  # Set the title for the heatmap\n",
    "plt.show()  # Display the heatmap\n",
    "\n",
    "# Plot a boxplot to show the relationship between House Age and Median House Value\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='HouseAge', y='MedHouseVal', data=train_data)  # Boxplot of House Age against Median House Value\n",
    "plt.title('Boxplot of House Value vs House Age')  # Set the title for the plot\n",
    "plt.xticks(rotation=90)  # Rotate the x-axis labels by 90 degrees for better readability\n",
    "plt.show()  # Display the plot\n",
    "\n",
    "# Plot a boxplot to show the relationship between Location Cluster (a new feature created from KMeans clustering) and Median House Value\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='LocationCluster', y='MedHouseVal', data=train_data)  # Boxplot of Location Cluster against Median House Value\n",
    "plt.title('Boxplot of House Value vs Location Cluster')  # Set the title for the plot\n",
    "plt.show()  # Display the plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d97f11",
   "metadata": {},
   "source": [
    "## Part 4 - Training \n",
    "Use the best combination of feature engineering, model (algorithm and hyperparameters) from the experiment part (part 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93713ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 4 - Training\n",
    "\n",
    "# Performing Grid Search to find the best hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # Grid search on different numbers of trees\n",
    "    'max_depth': [10, 20, None]  # Grid search on different max depth values\n",
    "}\n",
    "\n",
    "model_rf = RandomForestRegressor()  # Initializing the model without specific parameters\n",
    "grid_search = GridSearchCV(model_rf, param_grid, cv=5, scoring='neg_mean_squared_error')  # Performing 5-fold cross-validation on the grid search\n",
    "grid_search.fit(X_train_scaled, y_train)  # Fitting the grid search on the training data\n",
    "\n",
    "# Displaying the best hyperparameters\n",
    "print(\"Best Parameters: \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259ab902",
   "metadata": {},
   "source": [
    "## Part 5 - Apply on test and show model performance estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9971aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 5 - Apply on test and show model performance estimation\n",
    "\n",
    "# Making predictions using the best estimator from GridSearchCV\n",
    "y_pred = grid_search.best_estimator_.predict(X_test_scaled)\n",
    "\n",
    "# Calculating the RMSE for model performance\n",
    "rmse = np.sqrt(mean_squared_error(test_data['MedHouseVal'], y_pred))\n",
    "print(\"Test RMSE: \", rmse)\n",
    "\n",
    "# Displaying the first five predictions\n",
    "print(\"Predictions on test set: \", y_pred[:5])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
